/**
*
*ImageProcessing
*
*
*
*/


#include "stdafx.h"
#include "ImageProcessing.h"

#include <fstream>


ADTF_FILTER_PLUGIN("ImageProcessing", OID_ADTF_ImageProcessing, cImageProcessing)

// define the ADTF property names to avoid errors 

#define LT_PROP_CAMERA_OFFSET "LaneDetection::Camera Offset"
#define LT_PROP_TRESHOLD "LaneDetection::ThresholdValue"

#define ImageProcessing_PROP_ImagecutWidthLeft "ImageProcessing::ImagecutWidthLeft"
#define ImageProcessing_PROP_ImagecutWidthRight "ImageProcessing::ImagecutWidthRight"
#define ImageProcessing_PROP_ImagecutHeightUp "ImageProcessing::ImagecutHeightUp"
#define ImageProcessing_PROP_ImagecutHeightDown "ImageProcessing::ImagecutHeightDown"

#define LT_PROP_SHOW_DEBUG "Common::Show Debug"





#define MAX_DEVIATION 150


//TODO 1
//#define LT_ENABLE_CANNY_WINDOWS


cImageProcessing::cImageProcessing(const tChar* __info) : cFilter(__info)
{


    
    SetPropertyBool(LT_PROP_SHOW_DEBUG, tFalse);
    SetPropertyStr(LT_PROP_SHOW_DEBUG NSSUBPROP_DESCRIPTION, "If true, the opencv windows will be shown and the gcl output is enabled.");
;

	SetPropertyInt(ImageProcessing_PROP_ImagecutWidthLeft, 60);
	SetPropertyInt(ImageProcessing_PROP_ImagecutWidthLeft NSSUBPROP_MIN, 0);
    SetPropertyStr(ImageProcessing_PROP_ImagecutWidthLeft NSSUBPROP_DESCRIPTION, "Cuts the Image...");

	SetPropertyInt(ImageProcessing_PROP_ImagecutWidthRight, 120);
	SetPropertyInt(ImageProcessing_PROP_ImagecutWidthRight NSSUBPROP_MIN, 0);
    SetPropertyStr(ImageProcessing_PROP_ImagecutWidthRight NSSUBPROP_DESCRIPTION, "Cuts the Image...");

	SetPropertyInt(ImageProcessing_PROP_ImagecutHeightUp, 240);
	SetPropertyInt(ImageProcessing_PROP_ImagecutHeightUp NSSUBPROP_MIN, 0);
    SetPropertyStr(ImageProcessing_PROP_ImagecutHeightUp NSSUBPROP_DESCRIPTION, "Cuts the Image...");

	SetPropertyInt(ImageProcessing_PROP_ImagecutHeightDown, 480);
	SetPropertyInt(ImageProcessing_PROP_ImagecutHeightDown NSSUBPROP_MIN, 0);
    SetPropertyStr(ImageProcessing_PROP_ImagecutHeightDown NSSUBPROP_DESCRIPTION, "Cuts the Image...");



    SetPropertyFloat(LT_PROP_CAMERA_OFFSET, 15);
    SetPropertyBool(LT_PROP_CAMERA_OFFSET NSSUBPROP_ISCHANGEABLE, tTrue);
    SetPropertyStr(LT_PROP_CAMERA_OFFSET NSSUBPROP_DESCRIPTION, "The offset of the camera in relation to the center of the car.");


    SetPropertyInt(LT_PROP_TRESHOLD, 150);
    SetPropertyBool(LT_PROP_TRESHOLD NSSUBPROP_ISCHANGEABLE, tTrue);
    SetPropertyStr(LT_PROP_TRESHOLD NSSUBPROP_DESCRIPTION, "The threshold value for canny to detect lines.");
    


    m_pISignalRegistry = NULL;
}

cImageProcessing::~cImageProcessing()
{
}

tResult cImageProcessing::GetInterface(const tChar* idInterface,
    tVoid** ppvObject)
{
    if (idmatch(idInterface, IID_ADTF_SIGNAL_PROVIDER))
    {
        *ppvObject = static_cast<ISignalProvider*> (this);
    }
    else
    {
        return cFilter::GetInterface(idInterface, ppvObject);
    }

    Ref();

    RETURN_NOERROR;
}

tUInt cImageProcessing::Ref()
{
    return cFilter::Ref();
}

tUInt cImageProcessing::Unref()
{
    return cFilter::Unref();
}

tVoid cImageProcessing::Destroy()
{
    delete this;
}

tResult cImageProcessing::Start(__exception)
{
    return cFilter::Start(__exception_ptr);
}

tResult cImageProcessing::Stop(__exception)
{

// TODO 1
#ifdef LT_ENABLE_CANNY_WINDOWS
    if(m_bShowDebug)
    {
        //destroyWindow("Canny Near");
        //destroyWindow("Canny Far");
        //destroyWindow("RGB Image");
        destroyWindow("Canny");
        //destroyWindow("GreyScale Image");
        //destroyWindow("Binary Image");
        //destroyWindow("Canny Image");
        //destroyWindow("LaneTracking");  
    }  
#endif    

    return cFilter::Stop(__exception_ptr);
}
tResult cImageProcessing::Init(tInitStage eStage, __exception )
{
    RETURN_IF_FAILED(cFilter::Init(eStage, __exception_ptr));

    if (eStage == StageFirst)
    {
        cObjectPtr<IMediaDescriptionManager> pDescManager;
        RETURN_IF_FAILED(_runtime->GetObject(OID_ADTF_MEDIA_DESCRIPTION_MANAGER,IID_ADTF_MEDIA_DESCRIPTION_MANAGER,(tVoid**)&pDescManager,__exception_ptr));

        // Media Description Signal
        tChar const * strDescSignalValue = pDescManager->GetMediaDescription("tSignalValue");
        RETURN_IF_POINTER_NULL(strDescSignalValue);        
        cObjectPtr<IMediaType> pTypeSignalValue = new cMediaType(0, 0, 0, "tSignalValue", strDescSignalValue,IMediaDescription::MDF_DDL_DEFAULT_VERSION);    
        RETURN_IF_FAILED(pTypeSignalValue->GetInterface(IID_ADTF_MEDIA_TYPE_DESCRIPTION, (tVoid**)&m_pCoderDescSignal)); 
        
        // Media Description Bool
        tChar const * strDescSignalBoolValue = pDescManager->GetMediaDescription("tBoolSignalValue");
        RETURN_IF_POINTER_NULL(strDescSignalBoolValue);
        cObjectPtr<IMediaType> pTypeSignalBoolValue = new cMediaType(0, 0, 0, "tBoolSignalValue", strDescSignalBoolValue,IMediaDescription::MDF_DDL_DEFAULT_VERSION);    
        RETURN_IF_FAILED(pTypeSignalBoolValue->GetInterface(IID_ADTF_MEDIA_TYPE_DESCRIPTION, (tVoid**)&m_pCoderDescBool));
     

        // Video Input
        RETURN_IF_FAILED(m_oVideoInputPin.Create("Video_Input", IPin::PD_Input, static_cast<IPinEventSink*>(this)));
        RETURN_IF_FAILED(RegisterPin(&m_oVideoInputPin));

        RETURN_IF_FAILED(m_oInputStart.Create("start", new cMediaType(0, 0, 0, "tBoolSignalValue"), static_cast<IPinEventSink*> (this)));
        RETURN_IF_FAILED(RegisterPin(&m_oInputStart));

        //GLC Output
        cObjectPtr<IMediaType> pCmdType = NULL;
        RETURN_IF_FAILED(AllocMediaType(&pCmdType, MEDIA_TYPE_COMMAND, MEDIA_SUBTYPE_COMMAND_GCL, __exception_ptr));
        RETURN_IF_FAILED(m_oGCLOutput.Create("GLC_Output",pCmdType, static_cast<IPinEventSink*> (this)));
        RETURN_IF_FAILED(RegisterPin(&m_oGCLOutput));


              
    }
    else if (eStage == StageNormal)
    {
        m_bFirstFrame = true;
        m_ui8Imagecount = 0;

        ReadProperties(NULL);

 
       

        m_ui8InitCtrl = 0;
        
        
        
        if (m_bShowDebug)
        {
        }

    }
    RETURN_NOERROR;
}

tResult cImageProcessing::PropertyChanged(const char* strProperty)
{
    ReadProperties(strProperty);

    RETURN_NOERROR;
}

tResult cImageProcessing::ReadProperties(const tChar* strPropertyName)
{
    

    if (NULL == strPropertyName || cString::IsEqual(strPropertyName, LT_PROP_CAMERA_OFFSET))
    {
        m_f64CamOffset = GetPropertyFloat(LT_PROP_CAMERA_OFFSET);
        m_sLaneCenterNear.x = 320 + static_cast<tInt16> (m_f64CamOffset);
        m_sPlaceToBe.x = 320 + static_cast<tInt16> (m_f64CamOffset);
    }



    if (NULL == strPropertyName || cString::IsEqual(strPropertyName, LT_PROP_TRESHOLD))
    {
        m_nThresholdValue = GetPropertyInt(LT_PROP_TRESHOLD);
    }

    if (NULL == strPropertyName || cString::IsEqual(strPropertyName, LT_PROP_SHOW_DEBUG))
    {
        m_bShowDebug = GetPropertyBool(LT_PROP_SHOW_DEBUG);
    }

	if (NULL == strPropertyName || cString::IsEqual(strPropertyName, ImageProcessing_PROP_ImagecutWidthLeft))
    {
        m_nImagecutWidthLeft = GetPropertyInt(ImageProcessing_PROP_ImagecutWidthLeft);
	}

	if (NULL == strPropertyName || cString::IsEqual(strPropertyName, ImageProcessing_PROP_ImagecutWidthRight))
    {
        m_nImagecutWidthRight = GetPropertyInt(ImageProcessing_PROP_ImagecutWidthRight);
	}

	if (NULL == strPropertyName || cString::IsEqual(strPropertyName, ImageProcessing_PROP_ImagecutHeightUp))
    {
        m_nImagecutHeightUp = GetPropertyInt(ImageProcessing_PROP_ImagecutHeightUp);
	}

	if (NULL == strPropertyName || cString::IsEqual(strPropertyName, ImageProcessing_PROP_ImagecutHeightDown))
    {
        m_nImagecutHeightDown = GetPropertyInt(ImageProcessing_PROP_ImagecutHeightDown);
	}

    RETURN_NOERROR;
}

tResult cImageProcessing::Run(tInt nActivationCode, const tVoid* pvUserData, tInt szUserDataSize, ucom::IException** __exception_ptr)
{

    RETURN_NOERROR;
}

tResult cImageProcessing::Shutdown(tInitStage eStage, ucom::IException** __exception_ptr)
{
    if(m_bShowDebug && eStage == cFilter::StageNormal)
    {        
        ucom::cObjectPtr<ISignalRegistry> pSignalRegistry;
        if (IS_OK(_runtime->GetObject(OID_ADTF_SIGNAL_REGISTRY,
            IID_ADTF_SIGNAL_REGISTRY,
            (tVoid**)&pSignalRegistry)))
        {
            // Unregister the provider
            pSignalRegistry->UnregisterSignalProvider(this);
        }
        m_oActive.clear();

        m_oLock.Release();
    }

    
    return cFilter::Shutdown(eStage,__exception_ptr);
}

tResult cImageProcessing::OnPinEvent(IPin* pSource, tInt nEventCode, tInt nParam1, tInt nParam2, IMediaSample* pMediaSample)
{
    
    RETURN_IF_POINTER_NULL(pMediaSample);
    RETURN_IF_POINTER_NULL(pSource);
    if(nEventCode == IPinEventSink::PE_MediaSampleReceived)
    {
        tTimeStamp InputTimeStamp;
        InputTimeStamp = pMediaSample->GetTime();


        if(pSource == &m_oVideoInputPin)
        {
            //Videoformat
            if (m_bFirstFrame)
            {        
                cObjectPtr<IMediaType> pType;
                RETURN_IF_FAILED(m_oVideoInputPin.GetMediaType(&pType));
                cObjectPtr<IMediaTypeVideo> pTypeVideo;
                RETURN_IF_FAILED(pType->GetInterface(IID_ADTF_MEDIA_TYPE_VIDEO, (tVoid**)&pTypeVideo));
                const tBitmapFormat* pFormat = pTypeVideo->GetFormat();                                
                if (pFormat == NULL)
                {
                    LOG_ERROR("No Bitmap information found on pin \"input\"");
                    RETURN_ERROR(ERR_NOT_SUPPORTED);
                }
                m_sInputFormat.nPixelFormat = pFormat->nPixelFormat;
                m_sInputFormat.nWidth = pFormat->nWidth;
                m_sInputFormat.nHeight =  pFormat->nHeight;
                m_sInputFormat.nBitsPerPixel = pFormat->nBitsPerPixel;
                m_sInputFormat.nBytesPerLine = pFormat->nBytesPerLine;
                m_sInputFormat.nSize = pFormat->nSize;
                m_sInputFormat.nPaletteSize = pFormat->nPaletteSize;
                m_bFirstFrame = false;
            }

            ProcessInput(pMediaSample, InputTimeStamp);
        }
         
        else if(pSource == &m_oInputStart)
        {
            tBool bValue = tFalse;
            {   // focus for sample read lock
                __adtf_sample_read_lock_mediadescription(m_pCoderDescBool,pMediaSample,pCoder);

                pCoder->Get("bValue", (tVoid*)&bValue);           
            }
                
        }
              
        
        RETURN_NOERROR;
    }
    
    RETURN_NOERROR;
}

tResult cImageProcessing::ProcessInput(IMediaSample* pSample, tTimeStamp tsInputTime)
{
    if(m_ui8InitCtrl < 150)         // This loop is necessary to boot the car's controller (needs neutral signal for a certain time)
    {
       
        m_ui8InitCtrl++;
    }
    else
    {
        // VideoInput
        RETURN_IF_POINTER_NULL(pSample);

        const tVoid* l_pSrcBuffer;
    
        /*IplImage* img = cvCreateImageHeader(cvSize(m_sInputFormat.nWidth, m_sInputFormat.nHeight), IPL_DEPTH_8U, 3);
        RETURN_IF_FAILED(pSample->Lock(&l_pSrcBuffer));
    
        cvSetData(img, (tVoid*)l_pSrcBuffer, img->widthStep);
        Mat image(cvarrToMat(img));
        cvReleaseImage(&img);
        pSample->Unlock(l_pSrcBuffer);*/
    
        IplImage* oImg = cvCreateImageHeader(cvSize(m_sInputFormat.nWidth, m_sInputFormat.nHeight), IPL_DEPTH_8U, 3);
        RETURN_IF_FAILED(pSample->Lock(&l_pSrcBuffer));
        oImg->imageData = (char*)l_pSrcBuffer;
        Mat image(cvarrToMat(oImg));
        cvReleaseImage(&oImg);
        pSample->Unlock(l_pSrcBuffer);
///////////////////////////////////////
        
    
        // Transform image
        Mat m_matImageCut= image(cv::Range(m_nImagecutHeightUp, m_nImagecutHeightDown), cv::Range(m_nImagecutWidthLeft, m_nImagecutWidthRight)).clone(); //Cut Image      
        medianBlur(m_matImageCut, m_matImageCutmedian, 11); // Filter
        cvtColor(m_matImageCutmedian, m_matImageCutGrey ,CV_RGB2GRAY);// Grey Image
        threshold(m_matImageCutGrey, m_matImageCutThres, m_nThresholdValue, 500,THRESH_BINARY);// Generate Binary Image
        Canny(m_matImageCutThres, m_matImageCutCanny, 0, 2, 3, false);// Detect Edges
        // Threshold hier??????
		CreateAndTransmitGCL();
 

//////////////////////////////////////////////////////// TODO 1
			fstream f;
			f.open("Matrix.dat",ios::out);
			f << m_matImageCutCanny;
			f.close(); 


///////////////////////////////////////////////////  TODO 1 

#ifdef LT_ENABLE_CANNY_WINDOWS
        //**************** Show Image *************************
        if(m_bShowDebug)
        {
            if(m_ui8Imagecount > 2)
            {
                m_ui8Imagecount=0;
                //imshow("RGB Image", image);
                imshow("Canny", m_matImageCutCanny);
                //imshow("GreyScale Image", greyNear);
                //imshow("Binary Image", greythreshNear);
                //imshow("Canny Image", linecanny);
                //imshow("Canny Near", m_matLineCannyNear);
                //imshow("Canny Far", m_matLineCannyFar);
                waitKey(1);
            }
            m_ui8Imagecount++;
        }
        //********************************************************
#endif

        //********** Find horizontal line (for calibration only)**************
        //tInt edgerow = 0;
        //for(tInt row=cannysize.height;row>=1;row--)                                                                                                                                                                                  
        //{            
        //    if(linecanny.at<uchar>(row,cannysize.width/2)!=0) 
        //    {    
        //        edgerow = row;
        //        row = 0;
        //    }
        //}
        //LOG_INFO(cString::Format("Found edge at row: %i", edgerow));
        //********************************************************************    

        //LOG_INFO(cString::Format("lfdnr1: %i",lfdnr1));
    

    }

    RETURN_NOERROR;            
}


tResult cImageProcessing::ProcessFound()
{        

    RETURN_NOERROR;
}

tResult cImageProcessing::ProcessOutput()
{

    RETURN_NOERROR;
}



tResult cImageProcessing::GetSignalValue(tSignalID nSignalID, tSignalValue * pValue)
{
    


    RETURN_NOERROR;
}

/**
 *   Activates a signal.
 *   Activated signals send their values to the Signal Registry Service.
 */
tResult cImageProcessing::ActivateSignalEvents(tSignalID nSignalID, tTimeStamp nUpdateRate)
{     
    RETURN_NOERROR;
}

/**
 *   Deactivates a signal.
 */
tResult cImageProcessing::DeactivateSignalEvents(tSignalID nSignalID)
{
    RETURN_NOERROR;
}

tResult cImageProcessing::CreateAndTransmitGCL()
{
    // just draw gcl if the pin is connected and debug mode is enabled
    if (!m_oGCLOutput.IsConnected() || !m_bShowDebug)
    {
        RETURN_NOERROR;
    }

    // create a mediasample
    cObjectPtr<IMediaSample> pSample;
    RETURN_IF_FAILED(AllocMediaSample((tVoid**)&pSample));

    RETURN_IF_FAILED(pSample->AllocBuffer(8192));

    pSample->SetTime(_clock->GetStreamTime());

    tUInt32* aGCLProc;
    RETURN_IF_FAILED(pSample->WriteLock((tVoid**)&aGCLProc));

    tUInt32* pc = aGCLProc;

    // draw rectangle to scale the video display correctly
    cGCLWriter::StoreCommand(pc, GCL_CMD_FGCOL, cColor(0, 0, 0).GetRGBA());	
    cGCLWriter::StoreCommand(pc, GCL_CMD_DRAWRECT, 0, 0, m_sInputFormat.nWidth, m_sInputFormat.nHeight);

    // draw near and far area
    cGCLWriter::StoreCommand(pc, GCL_CMD_FGCOL, cColor(255, 0, 255).GetRGBA());
    cGCLWriter::StoreCommand(pc, GCL_CMD_DRAWRECT,m_nImagecutWidthLeft , m_nImagecutHeightUp, m_nImagecutWidthRight, m_nImagecutHeightDown);
    
    // draw the min and max lane width
    cGCLWriter::StoreCommand(pc, GCL_CMD_FGCOL, cColor(150,150,150).GetRGBA());


    // draw near and far line
    cGCLWriter::StoreCommand(pc, GCL_CMD_FGCOL, cColor(255,70,0).GetRGBA());
	
    
    // draw the lines for place to be and the detected lanecenter
    cGCLWriter::StoreCommand(pc, GCL_CMD_FGCOL, cColor(255,150,0).GetRGBA());

    cGCLWriter::StoreCommand(pc, GCL_CMD_END);

    pSample->Unlock(aGCLProc);

    RETURN_IF_FAILED(m_oGCLOutput.Transmit(pSample));
    RETURN_NOERROR;

}
